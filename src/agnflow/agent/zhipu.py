"""
API

- è¯­è¨€æ¨¡å‹: chat, assistant, agents
- å›¾åƒä¸è§†é¢‘: images, videos
- éŸ³é¢‘: audio
- æ–‡ä»¶ä¸æ‰¹é‡å¤„ç†: files, batches
- å‘é‡ä¸åµŒå…¥: embeddings
- çŸ¥è¯†ä¸å·¥å…·: knowledge, tools
- æ£€ç´¢ä¸æœç´¢: web_search
- å¾®è°ƒ: fine_tunin
- å†…å®¹å®‰å…¨: moderations

TODO

- è¯­è¨€æ¨¡å‹âœ…
- æ¨ç†æ¨¡å‹âœ…
- æ™ºèƒ½ä½“
- è§†è§‰æ¨ç†æ¨¡å‹âœ…
- æœç´¢å·¥å…·
- éŸ³è§†é¢‘âœ…
- è§†é¢‘ç”Ÿæˆæ¨¡å‹âœ…
- å›¾åƒç”Ÿæˆæ¨¡å‹âœ…
- Agentæ¨¡å‹
- ä»£ç æ¨¡å‹
- å‘é‡æ¨¡å‹
- å†…å®¹å®‰å…¨
- è§’è‰²æ‰®æ¼”æ¨¡å‹
- æ™ºèƒ½ä½“å¼€å‘å¹³å°
- æ‰¹é‡å¤„ç†
- æ–‡ä»¶ç®¡ç†

"""

import base64
import time
import os
from dotenv import load_dotenv
from typing import Callable, Literal, Annotated as A
import logging
import subprocess
import tempfile

from zhipuai import ZhipuAI
from zhipuai.core._sse_client import StreamResponse
from zhipuai.types.chat.async_chat_completion import AsyncCompletion
from zhipuai.types.chat.chat_completion_chunk import ChatCompletionChunk
from zhipuai.types.image import ImagesResponded
from zhipuai.types.video.video_object import VideoObject

from agnflow.agent.msg import AudioMsg, ImageMsg, Msg, UserMsg, VideoMsg, inject_tool

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


def zhipu_wait_for_result(model: Literal["chat", "video"], id: str, verbose: bool = False):
    """è·å–å¼‚æ­¥ä»»åŠ¡ç»“æœ"""
    client = ZhipuAI(api_key=os.getenv("API_KEY"))
    task_status = ""
    get_cnt = 0
    result: AsyncCompletion | VideoObject = None
    while task_status != "SUCCESS" and task_status != "FAILED" and get_cnt <= 40:
        if model == "chat":
            result = client.chat.asyncCompletions.retrieve_completion_result(id=id)
        elif model == "video":
            result = client.videos.retrieve_videos_result(id=id)
            verbose = True
        task_status = result.task_status
        time.sleep(2)
        get_cnt += 1
    return result if verbose else result.choices[0].message.content


def _stream_response_generator(
    response: StreamResponse[ChatCompletionChunk],
    verbose: bool = False,
    save_file: str = None,
    model: Literal["chat", "audio"] = "chat",
):
    """æµå¼è¾“å‡ºç”Ÿæˆå™¨"""
    i = 1
    for chunk in response:
        if verbose:
            yield chunk
        elif model == "chat":
            delta = chunk.choices[0].delta
            if save_file and (save_file.endswith(".wav") or save_file.endswith(".mp3")):
                filename = save_file.format(i=i)
                if delta.audio is not None:
                    if delta.audio.data is not None:
                        with open(filename, "wb") as wav_file:
                            wav_file.write(base64.b64decode(delta.audio.data))
                            i = i + 1
            yield delta.content or ""
        elif model == "audio":
            if hasattr(chunk, "delta"):
                yield chunk.delta or ""
            else:
                yield "[END]"
                yield chunk.text or ""

    response.response.close()


# ğŸ†“å…è´¹æ¨¡å‹
free_model_map = {
    None: "glm-4-flash-250414",
    "vision": "glm-4v-flash",
    "vision-thinking": "glm-4.1v-thinking-flash",
    "reasoning": "glm-z1-flash",
    "image": "cogview-3-flash",
    "video": "cogvideo-x-flash",
}


# æ£€æŸ¥å¹¶è½¬æ¢éŸ³é¢‘æ ¼å¼
def convert_to_mono(input_file: str) -> str:
    """å°†éŸ³é¢‘è½¬æ¢ä¸ºå•å£°é“"""
    try:
        # ä½¿ç”¨ ffmpeg è½¬æ¢ä¸ºå•å£°é“
        output_file = tempfile.mktemp(suffix=".wav")
        # ac 1 å•å£°é“
        # ar 16000 é‡‡æ ·ç‡16kHz
        # f wav è¾“å‡ºæ ¼å¼
        # y è¦†ç›–è¾“å‡ºæ–‡ä»¶
        cmd = ["ffmpeg", "-i", input_file, "-ac", "1", "-ar", "16000", "-f", "wav", "-y", output_file]
        subprocess.run(cmd, check=True, capture_output=True)
        return output_file
    except subprocess.CalledProcessError:
        print("âš ï¸  ffmpeg è½¬æ¢å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨åŸæ–‡ä»¶...")
        return input_file
    except FileNotFoundError:
        print("âš ï¸  æœªæ‰¾åˆ° ffmpegï¼Œè¯·å®‰è£…åé‡è¯•")
        return input_file


def zhipu_chat(
    messages: str | Msg,
    model: str = None,
    tools: list[Callable] = [],
    mode: Literal["sync", "async", "stream"] = "sync",
    temperature: float = 0.7,
    top_p: float = 1.0,
    verbose: bool = False,
    save_file: str = None,
    **kwargs,
):
    """æ™ºè°±AIè°ƒç”¨æ¥å£

    å‚æ•°
    - messages: æ¶ˆæ¯
    - model: æ¨¡å‹
    - tools: å·¥å…·
    - mode: æ¨¡å¼, sync: åŒæ­¥, async: å¼‚æ­¥, stream: æµå¼
    - temperature: æ¸©åº¦
    - top_p: ä¸Šæ–‡æ¦‚ç‡
    - verbose: è¯¦ç»†è¾“å‡º
    - **kwargs: æ¨¡å‹clientå…¶ä»–å‚æ•°

    ### å…è´¹æ¨¡å‹
    - glm-4-flash-250414 ï¼ˆmodel=Noneï¼‰
    - glm-4v-flash ï¼ˆmodel="vision"ï¼‰
    - glm-4.1v-thinking ï¼ˆmodel="vision-thinking"ï¼‰
    - glm-z1-flash ï¼ˆmodel="reasoning"ï¼‰
    - cogview-3-flash ï¼ˆmodel="image"ï¼‰
    - cogvideo-x-flash ï¼ˆmodel="video"ï¼‰

    ### è¯­è¨€æ¨¡å‹:ï¼ˆGLM-4ï¼‰
    - glm-4-flashï¼ˆå…è´¹ï¼‰
    - glm-4-plus
    - glm-4-air-250414
    - glm-4-airx
    - glm-4-long
    - glm-4-flashx
    - glm-4-flash-250414

    ### è§†è§‰æ¨¡å‹ï¼šï¼ˆGLM-4Vï¼‰
    - glm-4v-flashï¼ˆå…è´¹ï¼‰
    - glm-4v-plus-0111

    ### æ¨ç†æ¨¡å‹ï¼šï¼ˆGLM-Z1ï¼‰
    - glm-z1-flashï¼ˆå…è´¹ï¼‰
    - glm-z1-air
    - glm-z1-airx

    ### è§†è§‰æ¨ç†æ¨¡å‹ï¼šï¼ˆGLM-4.1Vï¼‰
    - glm-4.1v-thinking-flashx
    - glm-4.1v-thinking-flash

    ### éŸ³é¢‘
    - glm-4-voice
    """
    # å‚æ•°å¤„ç†
    model = free_model_map.get(model, model)
    if isinstance(messages, str):
        messages = UserMsg(messages)
    if tools:
        kwargs.update({"tools": tools, "tool_choice": "auto"})
    if mode == "stream":
        kwargs.update({"stream": True})

    # æ¨¡å‹è°ƒç”¨
    client = ZhipuAI(api_key=os.getenv("API_KEY"))
    completions = client.chat.asyncCompletions if mode == "async" else client.chat.completions
    response = completions.create(model=model, messages=messages, temperature=temperature, top_p=top_p, **kwargs)

    # ç»“æœè¿”å›
    if mode == "async":
        return lambda: zhipu_wait_for_result("chat", id=response.id, verbose=verbose)
    elif mode == "stream":
        return lambda: _stream_response_generator(response=response, verbose=verbose, save_file=save_file, model="chat")
    elif verbose:
        return response
    elif mode == "sync":
        if tools:
            return response.choices[0].message.tool_calls
        if save_file and (save_file.endswith(".wav") or save_file.endswith(".mp3")):
            audio_data = response.choices[0].message.audio.data
            with open(save_file, "wb") as wav_file:
                wav_file.write(base64.b64decode(audio_data))
        return response.choices[0].message.content
    else:
        raise ValueError(f"Invalid mode: {mode}")


def zhipu_audio(
    file: str,
    model: str = "glm-asr",
    stream: bool = False,
    verbose: bool = False,
    **kwargs,
):
    """æ™ºè°±AIéŸ³é¢‘è½¬æ–‡å­—

    å‚æ•°
    - file: éŸ³é¢‘æ–‡ä»¶
    - model: æ¨¡å‹
    - stream: æµå¼
    - verbose: è¯¦ç»†è¾“å‡º
    - **kwargs: æ¨¡å‹clientå…¶ä»–å‚æ•°
    """
    # è½¬æ¢éŸ³é¢‘æ ¼å¼
    converted_file = convert_to_mono(file)

    client = ZhipuAI(api_key=os.getenv("API_KEY"))
    with open(converted_file, "rb") as audio_file:
        response = client.audio.transcriptions.create(model=model, file=audio_file, stream=stream, **kwargs)
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if converted_file != file and os.path.exists(converted_file):
            os.remove(converted_file)

        if stream:
            return lambda: _stream_response_generator(response=response, model="audio", verbose=verbose)
        else:
            return response if verbose else response.text


def zhipu_video(
    prompt: str = None,
    image_url: str = None,
    model: str = "cogvideox-flash",
    quality: Literal["quality", "speed"] = "quality",
    with_audio: bool = True,
    size: str = "1920x1080",
    fps: int = 30,
    **kwargs,
):
    """æ–‡ç”Ÿè§†é¢‘ï¼Œå›¾ç”Ÿè§†é¢‘

    å‚æ•°
    - file: è§†é¢‘æ–‡ä»¶
    - model: æ¨¡å‹
    - prompt: æ–‡ç”Ÿè§†é¢‘æç¤º
    - image_url: å›¾ç”Ÿè§†é¢‘å›¾ç‰‡url
    - quality: è¾“å‡ºæ¨¡å¼ï¼Œ"quality"ä¸ºè´¨é‡ä¼˜å…ˆï¼Œ"speed"ä¸ºé€Ÿåº¦ä¼˜å…ˆ
    - with_audio: æ˜¯å¦åŒ…å«éŸ³é¢‘
    - size: è§†é¢‘åˆ†è¾¨ç‡ï¼Œæ”¯æŒæœ€é«˜4Kï¼ˆå¦‚: "3840x2160"ï¼‰
    - fps: å¸§ç‡ï¼Œå¯é€‰ä¸º30æˆ–60
    - **kwargs: æ¨¡å‹clientå…¶ä»–å‚æ•°

    æ¨¡å‹
    - cogvideox-2
    - cogvideox-flashï¼ˆå…è´¹ï¼‰

    æœªæ”¯æŒæ¨¡å‹ï¼šviduç³»åˆ—
    """
    client = ZhipuAI(api_key=os.getenv("API_KEY"))
    response: VideoObject = client.videos.generations(
        model=model, prompt=prompt, image_url=image_url, quality=quality, with_audio=with_audio, size=size, fps=fps
    )

    return lambda: zhipu_wait_for_result(model="video", id=response.id)


def zhipu_image(prompt: str = None, model: str = "cogview-3-flash", verbose: bool = False, **kwargs):
    """æ–‡ç”Ÿå›¾

    å‚æ•°
    - prompt: æ–‡ç”Ÿå›¾æç¤º
    - model: æ¨¡å‹
    - verbose: è¯¦ç»†è¾“å‡º
    - **kwargs: æ¨¡å‹clientå…¶ä»–å‚æ•°

    æ¨¡å‹ï¼š
    - cogview-4-250304
    - cogview-4
    - cogview-3-flashï¼ˆå…è´¹ï¼‰
    """
    client = ZhipuAI(api_key=os.getenv("API_KEY"))
    response: ImagesResponded = client.images.generations(model=model, prompt=prompt, **kwargs)

    return response if verbose else response.data[0].url


def zhipu_agent():
    """æ™ºè°±AIæ™ºèƒ½ä½“

    æ™ºèƒ½ä½“
    - é€šç”¨ç¿»è¯‘:
    - ä¸“ä¸šæ–‡æ¡£ç¿»è¯‘: doc_translation_agent
    - ç¤¾ç§‘æ–‡å­¦ç¿»è¯‘
    - å½±è§†å‰§å­—å¹•ç¿»è¯‘
    - ç¤¾äº¤åª’ä½“ç¿»è¯‘
    - AIç»˜å›¾
    - AIæ¼«ç”»
    - çƒ­é—¨ç‰¹æ•ˆè§†é¢‘
    - ç®€å†ä¸å²—ä½åŒ¹é…åŠ©æ‰‹
    - å®¢æœè¯æœ¯è´¨æ£€ service_check_agent
    - é”€å”®è´¨æ£€ sales_check_agent
    - ç¥¨æ®è¯†åˆ« bill_recognition_agent
    - è¡£ç‰©è¯†åˆ« clothes_recognition_agent
    - åˆåŒè§£æ contract_parser_agent
    - æ‹›æ ‡è§£ææ™ºèƒ½ä½“ bidding_parser_agent
    - ä¸­æ ‡è§£ææ™ºèƒ½ä½“ bidwin_parser_agent
    - æ™ºèƒ½è§£é¢˜ intelligent_education_solve_agent
    - ä½œä¸šæ‰¹æ”¹ intelligent_education_correction_agent
    """
    pass


msg_texts = {
    "æ™ºèƒ½å†™ä½œ": """-ä¸Šä¸‹æ–‡ï¼šæˆ‘æƒ³æ¨å¹¿å…¬å¸çš„æ–°äº§å“ã€‚æˆ‘çš„å…¬å¸åä¸ºï¼šæ™ºè°±AIï¼Œæ–°äº§å“åä¸ºï¼šChatGLMå¤§æ¨¡å‹ï¼Œæ˜¯ä¸€æ¬¾é¢å‘å¤§ä¼—çš„AIäº§å“ã€‚
-ç›®æ ‡ï¼šå¸®æˆ‘åˆ›å»ºä¸€æ¡å°çº¢ä¹¦å¹³å°çš„å¸–å­ï¼Œç›®çš„æ˜¯å¸å¼•äººä»¬ç‚¹å‡»äº§å“é“¾æ¥è¿›è¡Œå­¦ä¹ å’Œä½“éªŒã€‚
-é£æ ¼ï¼šå‚ç…§Dysonç­‰æˆåŠŸå…¬å¸çš„å®£ä¼ é£æ ¼ï¼Œå®ƒä»¬åœ¨æ¨å¹¿ç±»ä¼¼äº§å“æ—¶çš„æ–‡æ¡ˆé£æ ¼ï¼ŒåŒæ—¶ç»“åˆå°çº¢ä¹¦çš„æ–‡æ¡ˆé£æ ¼ã€‚
-è¯­è°ƒï¼šè¯´æœæ€§
-å—ä¼—ï¼šAIäº§å“åœ¨å°çº¢ä¹¦ä¸Šçš„ä¸»è¦å—ä¼—æ˜¯å¹´è½»äººï¼Œæ´»è·ƒåœ¨äº’è”ç½‘å’ŒAIé¢†åŸŸã€‚è¯·é’ˆå¯¹è¿™ä¸€ç¾¤ä½“åœ¨é€‰æ‹©æŠ¤å‘äº§å“æ—¶çš„å…¸å‹å…³æ³¨ç‚¹æ¥å®šåˆ¶å¸–å­ã€‚
-å“åº”ï¼šä¿æŒå°çº¢ä¹¦å¸–å­ç®€æ´è€Œæ·±å…·å½±å“åŠ›ï¼Œæ³¨æ„è¦ä½¿ç”¨emojiè¡¨æƒ…ï¼Œ
    **å¹³å°é“¾æ¥ä»¥markdownæ ¼å¼è¾“å‡ºæ˜¾ç¤º**ï¼šï¼»æ™ºè°±AIå¼€æ”¾å¹³å°ï¼½ï¼ˆhttps://open.bigmodel.cn/console/trialcenterï¼‰ã€‚
    **å¹³å°logoæ”¾åœ¨æ–‡æ¡ˆæœ€ä¸‹æ–¹**ï¼š"Dï¼ˆhttps://s21.ax1x.com/2024/12/17/pALCRaT.png)*""",
    "æ™ºèƒ½ç¿»è¯‘": """ç¿»è¯‘ä»¥ä¸‹èå£«æ¯”äºšæˆå‰§ã€Šç½—å¯†æ¬§ä¸æœ±ä¸½å¶ã€‹ä¸­çš„é€‰æ®µï¼š
\"To be, or not to be: that is the question:Whether 'tis nobler in the mind to suffer The slings and arrows of outrageous fortune,Or to take arms against a sea of troubles And by opposing end them.\"""",
    "å®ä½“æŠ½å–": """ä½ ç°åœ¨æ˜¯ä¸€ä¸ªæ³•å¾‹ä¸“å®¶ï¼Œè¯·ä½ å¯¹è¿™ç¯‡åˆ¤å†³ä¹¦çš„å†…å®¹è¿›è¡Œåˆ†æã€‚ä¸è¦å±•ç°åˆ†æè¿‡ç¨‹ï¼Œç›´æ¥æŒ‰ç…§ä¸‹é¢çš„æ ¼å¼è¾“å‡º
## åˆ¤å†³ä¹¦å†…å®¹ï¼š
    ä¸­åäººæ°‘å…±å’Œå›½æœ€é«˜äººæ°‘æ³•é™¢
        æŒ‡å®šç®¡è¾–å†³å®šä¹¦
    ï¼ˆ2017ï¼‰æœ€é«˜æ³•åˆ‘è¾– 19 å·
    å…³äºè¢«å‘Šå•ä½åŒ—äº¬ç›˜å¤æ°æŠ•èµ„æœ‰é™å…¬å¸æ¶‰å«Œéª—å–è´·æ¬¾ã€è¢«å‘Šäººå•æ¶›ç­‰å…«äººæ¶‰å«Œéª—å–è´·æ¬¾ã€éª—è´­å¤–æ±‡ã€éå›½å®¶å·¥ä½œäººå‘˜å—è´¿ã€éæ³•æ‹˜ç¦ã€æ•…æ„æ¯åä¼šè®¡å‡­è¯ã€ä¼šè®¡è´¦ç°¿ã€è´¢åŠ¡ä¼šè®¡æŠ¥å‘Šç­‰çŠ¯ç½ªæ¡ˆä»¶ï¼Œæœ¬é™¢ç»å®¡æŸ¥ï¼Œä¾ç…§ã€Šä¸­åäººæ°‘å…±å’Œå›½åˆ‘äº‹è¯‰è®¼æ³•ã€‹ç¬¬äºŒåå…­æ¡çš„è§„å®šï¼Œå†³å®šå¦‚ä¸‹ï¼šæŒ‡å®šè¾½å®çœå¤§è¿å¸‚è¥¿å²—åŒºäººæ°‘æ³•é™¢ä¾ç…§åˆ‘äº‹ç¬¬ä¸€å®¡ç¨‹åºå¯¹è¯¥æ¡ˆè¿›è¡Œå®¡åˆ¤ã€‚  äºŒã€‡ä¸€ä¸ƒå¹´ä¸‰æœˆåä¸ƒæ—¥
## å®šä¹‰è¾“å‡ºæ ¼å¼
{
    "çŠ¯ç½ªå®¢ä½“": {
        "æ¶‰åŠå®¢ä½“": ""
    },
    "çŠ¯ç½ªä¸»è§‚è¦ä»¶-ç½ªè¿‡å½¢å¼": {
        "æ•…æ„": "",
        "è¿‡å¤±": ""
    },
    "çŠ¯ç½ªä¸»è§‚è¦ä»¶": {
        "çŠ¯ç½ªåŠ¨æœº": "",
        "çŠ¯ç½ªç›®çš„": "",
        "çŠ¯ç½ªåœ°ç‚¹": ""
    },
    "çŠ¯ç½ªå®¢è§‚è¦ä»¶": {
        "çŠ¯ç½ªåœ°ç‚¹": "",
        "çŠ¯ç½ªè¡Œä¸º": "",
        "çŠ¯ç½ªè¿‡ç¨‹": ""
    },
    "é€‚ç”¨æ³•æ¡": "",
    "åˆ¤å†³ç»“æœæ—¶é—´": "",
    "åˆ¤å†³åˆ‘æœŸ": "",
    "åˆ¤å†³ç»“æœé‡‘é¢": ""
}
""",
}


@inject_tool
def query_train_info(
    departure: A[str, "å‡ºå‘åŸå¸‚æˆ–è½¦ç«™"], destination: A[str, "ç›®çš„åœ°åŸå¸‚æˆ–è½¦ç«™"], date: A[str, "è¦æŸ¥è¯¢çš„ç«è½¦æ—¥æœŸ"]
) -> str:
    """æ ¹æ®ç”¨æˆ·æä¾›çš„ä¿¡æ¯æŸ¥è¯¢ç«è½¦æ—¶åˆ»"""
    return "2024å¹´1æœˆ1æ—¥ä»åŒ—äº¬å—ç«™åˆ°ä¸Šæµ·çš„ç«è½¦ç¥¨"


msg_images = {
    "å›¾åƒæè¿°ç”Ÿæˆ": ImageMsg(
        "å¯¹å›¾åƒè¿›è¡Œè¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬ä¸»è¦å…ƒç´ ã€åœºæ™¯ã€é¢œè‰²ç­‰ã€‚",
        "https://cdn.bigmodel.cn/markdown/1735118177180image.png?attname=image.png",
    ),
    "å›¾åƒåˆ†ç±»": ImageMsg(
        "ä»”ç»†è§‚å¯Ÿå›¾åƒï¼Œç»™å‡ºå›¾åƒä¸­çš„ç‹—å“ç§ã€‚",
        "https://cdn.bigmodel.cn/markdown/1735118460293image.png?attname=image.png",
    ),
    "è§†è§‰æ¨ç†": ImageMsg(
        "æ ¹æ®å›¾ä¸­çš„å†…å®¹ï¼Œæ¨æµ‹å‡ºå½“å¤©çš„å¤©æ°”", "https://cdn.bigmodel.cn/markdown/1735118533368image.png?attname=image.png"
    ),
    "è§†è§‰é—®ç­”ï¼ˆVQAï¼‰": ImageMsg(
        "ç»™ä½ åˆ†äº«ä¸€ä¸ªæˆ‘æœ€è¿‘çœ‹æ¼”å”±ä¼šçš„ç…§ç‰‡", "https://cdn.bigmodel.cn/markdown/1735118599591image.png?attname=image.png"
    ),
    "å›¾åƒæƒ…æ„Ÿåˆ†æ": ImageMsg(
        "åˆ†æå¹¶æè¿°å›¾åƒæ‰€ä¼ è¾¾çš„ä¸»è¦æƒ…æ„Ÿæˆ–æƒ…ç»ªã€‚",
        "https://cdn.bigmodel.cn/markdown/1735118688747image.png?attname=image.png",
    ),
    "å›¾è¡¨é—®ç­”": ImageMsg(
        "è¯·ä½ å¸®æˆ‘åˆ†æä¸€ä¸‹å›¾ç‰‡ä¸­çš„æˆ¿ä»·èµ°åŠ¿ï¼Œå¹¶é¢„æµ‹æ¥ä¸‹æ¥ä¸€å¹´çš„è¶‹åŠ¿æ˜¯ä»€ä¹ˆ",
        "http://cdn.bigmodel.cn/markdown/1735635250726æˆéƒ½äºŒæ‰‹æˆ¿ä»·ä»Šå¹´ä»·æ ¼å›¾.jpeg?attname=æˆéƒ½äºŒæ‰‹æˆ¿ä»·ä»Šå¹´ä»·æ ¼å›¾.jpeg",
    ),
    "ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆ": ImageMsg(
        "æ®å›¾ç‰‡å†…å®¹åˆ›ä½œä¸€ç¯‡å¸å¼•äººçš„å°çº¢ä¹¦ï¼ˆå¾’æ­¥æ—…è¡Œï¼‰æ–‡æ¡ˆ",
        "https://cdn.bigmodel.cn/markdown/1735118803138image.png?attname=image.png",
    ),
    "æ•™è‚²åº”ç”¨": ImageMsg(
        "å›¾ä¸­ååº”äº†ä»€ä¹ˆç‰©ç†å­¦ç°è±¡", "https://cdn.bigmodel.cn/markdown/1735118908375image.png?attname=image.png"
    ),
    "è´¨é‡æ£€æµ‹": ImageMsg(
        "è¯†åˆ«å›¾ä¸­æœ‰å‡ ä¸ªåæœ", "https://cdn.bigmodel.cn/markdown/1735119051024image.png?attname=image.png"
    ),
    "å•†å“æè¿°ç”Ÿæˆ": ImageMsg(
        "ç»™å›¾ä¸­çš„ç‰©å“ç”Ÿæˆä¸€ä¸ªå•†å“æ ‡é¢˜ï¼Œç”¨äºæ·˜å®å•†åº—!",
        "https://cdn.bigmodel.cn/markdown/1735119077344image.png?attname=image.png",
    ),
    "æ•°æ®æ ‡æ³¨": ImageMsg(
        "å‡†ç¡®è¯†åˆ«å›¾åƒä¸­æ±½è½¦çš„ç±»å‹å’Œé¢œè‰²ï¼Œå¹¶ä¸”æŒ‰ç…§ jsonæ ¼å¼è¾“å‡º",
        "https://cdn.bigmodel.cn/markdown/1735119156174image.png?attname=image.png",
    ),
    "ä¿é™©å•ä¿¡æ¯æå–": ImageMsg(
        """DEFINE ROLE AS "å‘ç¥¨è¯†åˆ«ä¸“å®¶":
    çŸ¥è¯†é¢†åŸŸ = [å‘ç¥¨è¯†åˆ«ã€ç¨åŠ¡ã€è´¢åŠ¡ä¼šè®¡]
    æŠ€èƒ½ = [æ–‡å­—è¯†åˆ«ã€ä¿¡æ¯æå–ã€æ ¼å¼éªŒè¯ã€æ•°æ®å¤„ç†]
    ç»éªŒ = "èµ„æ·±"
#å®šä¹‰å‘ç¥¨å­—æ®µç»“æ„
invoice_fields = {
  â€œå‘ç¥¨åŸºç¡€ä¿¡æ¯â€: {
        â€œå‘ç¥¨ç±»å‹â€: {â€œdescriptionâ€: â€œå‘ç¥¨ç§ç±»ï¼Œå¦‚å¢å€¼ç¨ç”µå­æ™®é€šå‘ç¥¨â€},
        â€œå‘ç¥¨ä»£ç â€: {â€œdescriptionâ€: â€œå‘ç¥¨å·¦ä¸Šè§’çš„10-12ä½æ•°å­—ä»£ç â€},
        â€œå‘ç¥¨å·ç â€: {â€œdescriptionâ€: â€œå‘ç¥¨å³ä¸Šè§’çš„8ä½æ•°å­—â€},
        â€œå¼€ç¥¨æ—¥æœŸâ€: {â€œdescriptionâ€: â€œæ ¼å¼ä¸ºYYYYå¹´MMæœˆDDæ—¥â€},
        â€œæ ¡éªŒç â€: {â€œdescriptionâ€: â€œå‘ç¥¨å³ä¸Šè§’çš„æ ¡éªŒç â€},
        â€œæœºå™¨ç¼–å·â€: {â€œdescriptionâ€: â€œå‘ç¥¨æœºå™¨ç¼–å·â€}
  },
  â€œè´­ä¹°æ–¹ä¿¡æ¯â€: {
        â€œåç§°â€: {â€œdescriptionâ€: â€œè´­ä¹°æ–¹å®Œæ•´åç§°â€},
        â€œçº³ç¨äººè¯†åˆ«å·â€: {â€œdescriptionâ€: â€œè´­ä¹°æ–¹çš„ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç â€},
        â€œåœ°å€ç”µè¯â€: {â€œdescriptionâ€: â€œè´­ä¹°æ–¹çš„åœ°å€å’Œè”ç³»ç”µè¯â€},
        â€œå¼€æˆ·è¡ŒåŠè´¦å·â€: {â€œdescriptionâ€: â€œè´­ä¹°æ–¹çš„å¼€æˆ·é“¶è¡ŒåŠè´¦å·â€}
  },
  â€œé”€å”®æ–¹ä¿¡æ¯â€: {
        â€œåç§°â€: {â€œdescriptionâ€: â€œé”€å”®æ–¹å®Œæ•´åç§°â€},
        â€œçº³ç¨äººè¯†åˆ«å·â€: {â€œdescriptionâ€: â€œé”€å”®æ–¹çš„ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç â€},
        â€œåœ°å€ç”µè¯â€: {â€œdescriptionâ€: â€œé”€å”®æ–¹çš„åœ°å€å’Œè”ç³»ç”µè¯â€},
        â€œå¼€æˆ·è¡ŒåŠè´¦å·â€: {â€œdescriptionâ€: â€œé”€å”®æ–¹çš„å¼€æˆ·é“¶è¡ŒåŠè´¦å·â€}
  },
  â€œå•†å“ä¿¡æ¯â€: {
        â€œè´§ç‰©æˆ–åº”ç¨åŠ³åŠ¡æœåŠ¡åç§°â€: {â€œdescriptionâ€: â€œå•†å“æˆ–æœåŠ¡çš„åç§°â€},
        â€œè§„æ ¼å‹å·â€: {â€œdescriptionâ€: â€œå•†å“çš„è§„æ ¼å‹å·â€},
        â€œå•ä½â€: {â€œdescriptionâ€: â€œè®¡é‡å•ä½â€},
        â€œæ•°é‡â€: {â€œdescriptionâ€: â€œå•†å“æ•°é‡â€},
        â€œå•ä»·â€: {â€œdescriptionâ€: â€œå•†å“å•ä»·â€}
  },
  â€œé‡‘é¢ä¿¡æ¯â€: {
        â€œé‡‘é¢â€: {â€œdescriptionâ€: â€œä¸å«ç¨é‡‘é¢â€},
        â€œç¨ç‡â€: {â€œdescriptionâ€: â€œé€‚ç”¨ç¨ç‡â€},
        â€œç¨é¢â€: {â€œdescriptionâ€: â€œç¨æ”¶é‡‘é¢â€},
        â€œä»·ç¨åˆè®¡_å¤§å†™â€: {â€œdescriptionâ€: â€œå«ç¨æ€»é‡‘é¢çš„ä¸­æ–‡å¤§å†™â€},
        â€œä»·ç¨åˆè®¡_å°å†™â€: {â€œdescriptionâ€: â€œå«ç¨æ€»é‡‘é¢çš„æ•°å­—è¡¨ç¤ºâ€}
  },
  â€œå¼€ç¥¨æ–¹ä¿¡æ¯â€: {
        â€œæ”¶æ¬¾äººâ€: {â€œdescriptionâ€: â€œæ”¶æ¬¾äººå§“åâ€},
        â€œå¤æ ¸äººâ€: {â€œdescriptionâ€: â€œå¤æ ¸äººå§“åâ€},
         â€œå¼€ç¥¨äººâ€: {â€œdescriptionâ€: â€œå¼€ç¥¨äººå§“åâ€},
        â€œé”€å”®æ–¹ç›–ç« â€: {â€œdescriptionâ€: â€œé”€å”®æ–¹çš„å°ç« ä¿¡æ¯â€}
  }
}

def extract_invoice_fields(image_content):
â€˜â€™â€˜â€™â€˜â€™
Step1: è¯†åˆ«å‘ç¥¨ç±»å‹
Step2: æŒ‰ç…§å„ç»´åº¦å®šä½å¹¶æå–å­—æ®µ
Step3: è¿›è¡Œå­—æ®µéªŒè¯å’Œæ ¼å¼åŒ–
Step4: è¿”å›ç»“æ„åŒ–æ•°æ®
â€˜â€™â€˜â€™â€˜â€™
output = {
        category: {field: â€œâ€ for field in fields.keys()}
        for category, fields in invoice_fields.items()
}
return output
MAIN PROCESS(image):
user_input = è¯»å–(â€˜â€™â€˜â€™â€˜â€™[image]â€˜â€™â€˜â€™â€˜â€™)
return extract_invoice_fields(user_input)

ä¸¥æ ¼æŒ‰ç…§jsonæ ¼å¼ï¼Œè¾“å‡ºMAIN PROCESSçš„æ‰§è¡Œç»“æœï¼Œç¦æ­¢é™„åŠ ä»»ä½•
çš„è§£é‡Š:""",
        "http://https://cdn.bigmodel.cn/http://markdown/1735637424313å±å¹•æˆªå›¾%202024-12-06%20143452.png?attname=å±å¹•æˆªå›¾+2024-12-06+143452.png",
    ),
    "è‚¤è´¨å›¾ç‰‡æµ‹è¯•å»ºè®®": ImageMsg(
        """ï¼ƒ Roleï¼š ä¸“ä¸šæŠ¤è‚¤é¡¾é—®
## Descriptionï¼šæˆ‘æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ¤è‚¤é¡¾é—®ï¼Œ æ“…é•¿é€šè¿‡å›¾ç‰‡åˆ†æè‚¤è´¨çŠ¶å†µï¼Œ
å¹¶æä¾›ä¸ªæ€§åŒ–çš„æŠ¤è‚¤å»ºè®®å’Œæ–¹æ¡ˆè§„åˆ’ã€‚
## Commands
/analyze- åˆ†æè‚¤è´¨çŠ¶å†µ
Idiagnose - é—®é¢˜è¯Šæ–­
/plan- æŠ¤è‚¤æ–¹æ¡ˆå®šåˆ¶
/routine - æ—¥å¸¸æŠ¤ç†å»ºè®®
/product - äº§å“ç±»å‹æ¨è
llifestyle - ç”Ÿæ´»ä¹ æƒ¯å»ºè®®
/progress - è·Ÿè¸ªæ”¹å–„è¿›åº¦
""",
        "https://cdn.bigmodel.cn/markdown/1735119024866image.png?attname=image.png",
    ),
}
msg_video = VideoMsg(
    "æè¿°ä¸€ä¸‹è§†é¢‘", "https://aigc-files.bigmodel.cn/api/cogvideo/be4922f6-5de4-11f0-afc2-be3559d9b1c6_0.mp4"
)


def pprint(*values, stream=False):
    """pretty print"""
    import json

    _values = []
    for value in values:
        if isinstance(value, (dict, list, tuple)):
            value = json.dumps(value, indent=4, ensure_ascii=False)
        _values.append(value)
    if stream:
        print(*_values, end="", flush=True)
    else:
        print(*_values)


if __name__ == "__main__":
    ...
    # ğŸš€ é—®ç­”
    # åŒæ­¥è°ƒç”¨
    response = zhipu_chat(messages=msg_texts["æ™ºèƒ½å†™ä½œ"], mode="sync")
    print(response)
    # æµå¼è¾“å‡º
    genertor = zhipu_chat(messages=msg_texts["å®ä½“æŠ½å–"], mode="stream")
    for chunk in genertor():
        pprint(chunk, stream=True)
    # å¼‚æ­¥è°ƒç”¨
    wait_for_result = zhipu_chat(messages=msg_texts["æ™ºèƒ½ç¿»è¯‘"], mode="async")
    print(wait_for_result())

    # ğŸ”§ å·¥å…·è°ƒç”¨
    msg = "ä½¿ç”¨å·¥å…·ï¼Œå¸®æˆ‘æŸ¥è¯¢ä»2024å¹´1æœˆ20æ—¥ï¼Œä»åŒ—äº¬å‡ºå‘å‰å¾€ä¸Šæµ·çš„èˆªç­"
    tool_calls = zhipu_chat(messages=msg, tools=[query_train_info.schema])
    print(tool_calls)

    # ğŸ“· å›¾ç‰‡æè¿°
    response = zhipu_chat(messages=msg_images["ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆ"], model="vision")
    print(response)

    # ğŸ¤” æ¨ç†
    msg = "ä¸€ä¸ªè¢‹å­ä¸­æœ‰5ä¸ªçº¢çƒå’Œ3ä¸ªè“çƒ,éšæœºæŠ½å–2ä¸ªçƒ,æŠ½åˆ°è‡³å°‘1ä¸ªçº¢çƒçš„æ¦‚ç‡ä¸º:"
    response = zhipu_chat(messages=msg, model="reasoning", mode="sync")
    print(response)  # åŒæ­¥è°ƒç”¨
    genertor = zhipu_chat(messages=msg, model="reasoning", mode="stream")
    for chunk in genertor():
        pprint(chunk, stream=True)  # æµå¼è¾“å‡º
    wait_for_result = zhipu_chat(messages=msg, model="reasoning", mode="async")
    print(wait_for_result())  # å¼‚æ­¥è°ƒç”¨

    # ğŸ‘ è§†è§‰æ¨ç†
    response = zhipu_chat(messages=msg_images["è§†è§‰æ¨ç†"], model="vision-thinking")
    print(response)

    # ğŸ¤ éŸ³é¢‘é—®ç­”
    # åŒæ­¥
    msg = AudioMsg("æ‚¨å¥½", "assets/hello.mp3")
    response = zhipu_chat(messages=msg, model="glm-4-voice", save_file="assets/output2.wav")
    print(response)
    # æµå¼
    msg = AudioMsg(url="assets/voice/hello.mp3")
    generator = zhipu_chat(messages=msg, model="glm-4-voice", save_file="assets/output3-{i}.wav", mode="stream")
    for chunk in generator():
        pprint(chunk, stream=True)

    # ğŸ¤ éŸ³é¢‘è½¬æ–‡å­—
    # åŒæ­¥
    response = zhipu_audio(file="assets/voice/hello.mp3", model="glm-asr")
    print(response)
    #  æµå¼
    generator = zhipu_audio(file="assets/voice/hello.mp3", model="glm-asr", stream=True)
    for chunk in generator(): 
        pprint(chunk, stream=True)

    # ğŸ¥ è§†é¢‘ç”Ÿæˆ
    wait_for_result = zhipu_video(prompt="ä¸€ä¸ªç¾ä¸½çš„å¥³å­©åœ¨æµ·è¾¹æ•£æ­¥")
    print(wait_for_result())

    # ğŸ¨ æ–‡ç”Ÿå›¾
    response = zhipu_image(prompt="ä¸€åªå¯çˆ±çš„å°çŒ«å’ª")
    print(response)
